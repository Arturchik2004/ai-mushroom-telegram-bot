import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import json
import os
import io

class MushroomPredictor:
    def __init__(self, model_path='model/mushroom_model.pth', config_path='model/config.json'):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"üß† –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –Ω–∞ {self.device}...")
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª–∞—Å—Å—ã
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"–ù–µ—Ç —Ñ–∞–π–ª–∞ {config_path}")
        with open(config_path, 'r') as f:
            self.classes = json.load(f)

        # 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
        self.model = models.efficientnet_b0(weights=None)
        num_ftrs = self.model.classifier[1].in_features
        self.model.classifier[1] = nn.Linear(num_ftrs, len(self.classes))
        
        # 3. –í–µ—Å–∞
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"–ù–µ—Ç —Ñ–∞–π–ª–∞ {model_path}")
            
        state_dict = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(state_dict)
        self.model.to(self.device)
        self.model.eval()
        
        # 4. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    def predict(self, image_input):
        """
        image_input: –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É (str) –ò–õ–ò –±–∞–π—Ç–æ–≤—ã–º –ø–æ—Ç–æ–∫–æ–º (io.BytesIO)
        """
        # PIL.Image.open –æ—Ç–ª–∏—á–Ω–æ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –∏ –ø—É—Ç–∏, –∏ –±–∞–π—Ç–æ–≤—ã–µ –ø–æ—Ç–æ–∫–∏
        image = Image.open(image_input).convert('RGB')
        
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(image_tensor)
            probs = torch.nn.functional.softmax(outputs, dim=1)
            top_p, top_class_idx = probs.topk(1, dim=1)
            
            return self.classes[top_class_idx.item()], top_p.item()